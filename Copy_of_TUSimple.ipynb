{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GyamfiKodie/Lane_Detection/blob/main/Copy_of_TUSimple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbSZDciY2VKG",
        "outputId": "24bc7675-ed66-4abd-ad66-71c5b6c8a257"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AfPm6A36p4L"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import numpy as np\n",
        "import json\n",
        "import cv2\n",
        "import os\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrlT1DaR89g_",
        "outputId": "63dd9ade-02a4-412b-8e40-6c60b3bcb74a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7ir-eDv7qUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa67f52b-d349-4d5a-86ca-0027b842d67a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed data saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "DATASET_PATH = \"/content/drive/MyDrive/Machine_Learning/Tusimple/train_set\"\n",
        "SAVE_PATH = \"/content/drive/MyDrive/Machine_Learning/Tusimple/processed_data\"  # Directory to save processed data\n",
        "\n",
        "# Ensure the save directory exists\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "\n",
        "# Function to load label data\n",
        "def load_labels(label_file):\n",
        "    with open(label_file, 'r') as f:\n",
        "        return [json.loads(line) for line in f]\n",
        "\n",
        "# Load all label data\n",
        "# Load all label data\n",
        "labels_0313 = load_labels(os.path.join(DATASET_PATH, '/content/drive/MyDrive/Machine_Learning/Tusimple/train_set/label_data_0313.json'))\n",
        "labels_0531 = load_labels(os.path.join(DATASET_PATH, '/content/drive/MyDrive/Machine_Learning/Tusimple/train_set/label_data_0531.json'))\n",
        "labels_0601 = load_labels(os.path.join(DATASET_PATH, '/content/drive/MyDrive/Machine_Learning/Tusimple/train_set/label_data_0601.json'))\n",
        "\n",
        "all_labels = labels_0313 + labels_0531 + labels_0601\n",
        "\n",
        "# Function to load images\n",
        "def load_images(label_data):\n",
        "    images = []\n",
        "    for item in label_data:\n",
        "        img_path = os.path.join(DATASET_PATH, item['raw_file'])\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (320, 160)) # Resize to a manageable size\n",
        "        images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Load images\n",
        "images = load_images(all_labels)\n",
        "\n",
        "# Function to create lane masks\n",
        "def create_lane_masks(label_data):\n",
        "    masks = []\n",
        "    for item in label_data:\n",
        "        mask = np.zeros((720, 1280)) # Assuming original size\n",
        "        lanes = item['lanes']\n",
        "        h_samples = item['h_samples']\n",
        "        for lane in lanes:\n",
        "            if lane.count(-2) < len(lane):  # if not all points are -2\n",
        "                for x, y in zip(lane, h_samples):\n",
        "                    if x != -2:\n",
        "                        cv2.circle(mask, (x, y), 5, 255, -1)  # Draw circles on lane points\n",
        "        mask = cv2.resize(mask, (320, 160))  # Resize to match image size\n",
        "        masks.append(mask)\n",
        "    return np.array(masks)\n",
        "\n",
        "# Create lane masks\n",
        "masks = create_lane_masks(all_labels)\n",
        "\n",
        "# Normalize images\n",
        "images = images / 255.0\n",
        "masks = masks / 255.0\n",
        "\n",
        "# Expand dimensions for masks to match the shape required by the model\n",
        "masks = np.expand_dims(masks, axis=-1)\n",
        "\n",
        "# Save the processed images and masks\n",
        "np.save(os.path.join(SAVE_PATH, 'images.npy'), images)\n",
        "np.save(os.path.join(SAVE_PATH, 'masks.npy'), masks)\n",
        "\n",
        "print(\"Processed data saved successfully!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the paths to the saved .npy files\n",
        "SAVE_PATH = \"/content/drive/MyDrive/Machine_Learning/Tusimple/processed_data\"\n",
        "IMAGES_PATH = os.path.join(SAVE_PATH, 'images.npy')\n",
        "MASKS_PATH = os.path.join(SAVE_PATH, 'masks.npy')\n",
        "\n",
        "# Load the processed images and masks\n",
        "images = np.load(IMAGES_PATH)\n",
        "masks = np.load(MASKS_PATH)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting arrays\n",
        "print(f\"Training images shape: {X_train.shape}\")\n",
        "print(f\"Training masks shape: {y_train.shape}\")\n",
        "print(f\"Validation images shape: {X_val.shape}\")\n",
        "print(f\"Validation masks shape: {y_val.shape}\")\n",
        "\n",
        "# Save the split data for future use\n",
        "np.save(os.path.join(SAVE_PATH, 'X_train.npy'), X_train)\n",
        "np.save(os.path.join(SAVE_PATH, 'y_train.npy'), y_train)\n",
        "np.save(os.path.join(SAVE_PATH, 'X_val.npy'), X_val)\n",
        "np.save(os.path.join(SAVE_PATH, 'y_val.npy'), y_val)\n",
        "\n",
        "print(\"Data split and saved successfully!\")\n"
      ],
      "metadata": {
        "id": "AhcLvdfpIedO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "\n",
        "# Define the paths to the saved .npy files\n",
        "SAVE_PATH = \"/content/drive/MyDrive/Machine_Learning/Tusimple/train_val\"\n",
        "X_TRAIN_PATH = os.path.join(SAVE_PATH, 'X_train.npy')\n",
        "Y_TRAIN_PATH = os.path.join(SAVE_PATH, 'y_train.npy')\n",
        "X_VAL_PATH = os.path.join(SAVE_PATH, 'X_val.npy')\n",
        "Y_VAL_PATH = os.path.join(SAVE_PATH, 'y_val.npy')\n",
        "\n",
        "# Load the training and validation data\n",
        "X_train = np.load(X_TRAIN_PATH)\n",
        "y_train = np.load(Y_TRAIN_PATH)\n",
        "X_val = np.load(X_VAL_PATH)\n",
        "y_val = np.load(Y_VAL_PATH)\n",
        "\n",
        "image_height = 160\n",
        "image_width = 320\n",
        "\n",
        "# Define your model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(image_height, image_width, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(UpSampling2D((2, 2)))\n",
        "model.add(Conv2D(1, (3, 3), activation='sigmoid', padding='same'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_val, y_val)\n",
        "print(\"Validation Loss:\", loss)\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJ25aNyxmoxs",
        "outputId": "3b14b9f3-8538-443c-de2c-402c717124a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1iYquzNHxfm6HusGBm1xNTY0ZnXj3BaTA",
      "authorship_tag": "ABX9TyPn+QmgAKtFqpO3DFAs6YAS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}